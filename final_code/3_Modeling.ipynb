{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "- ResNet50 + GPT2 이용\n",
    "- google colab 사용(GPU 환경)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드라이브 마운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab은 휘발성 특징으로 매번 설치 작업 필요\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.models as models # 이미지\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2Model # 텍스트\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드 \n",
    "방법 1. 구글 드라이브에 로컬에서 추출한 이미지 폴더 업로드 후 압축 풀기\n",
    " - 대용량 train 원본 이미지 데이터의 용량을 줄일 수 있음  \n",
    "  \n",
    "방법 2. 전체 train 이미지 폴더에서 바로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 방법 1\n",
    "\n",
    "# 압축을 풀 폴더 경로\n",
    "%cd /content/drive/MyDrive/Colab Notebooks/zerobase/DL_project/data/image\n",
    "\n",
    "!unzip -qq \"/content/drive/MyDrive/Colab Notebooks/data/zip file/train_10000.zip\"\n",
    "!unzip -qq \"/content/drive/MyDrive/Colab Notebooks/data/zip file/test_2000.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 방법 2\n",
    "text_train = pd.read_csv('./data/train.csv')\n",
    "train_path_10000 = text_train[text_train.answer.isin(['yes', 'no'])].image_id.value_counts()[:10000].index.to_list()\n",
    "test_path_2000 = text_train[text_train.answer.isin(['yes', 'no'])].image_id.value_counts()[10000:12000].index.to_list()\n",
    "\n",
    "\n",
    "# Train folder2 생성\n",
    "src = '/content/drive/MyDrive/Colab Notebooks/data/image/train/'\n",
    "dst = '/content/drive/MyDrive/Colab Notebooks/data/image/train_10000/'\n",
    "\n",
    "if not os.path.exists(dst):\n",
    "  os.makedirs(dst)\n",
    "\n",
    "for image in tqdm(train_path_10000):\n",
    "    source = src + image + '.jpg'\n",
    "    destination = dst + image + '.jpg'\n",
    "\n",
    "    shutil.copyfile(source, destination)\n",
    "\n",
    "\n",
    "# Test folder2 생성\n",
    "src = '/content/drive/MyDrive/Colab Notebooks/data/image/train/'\n",
    "dst = '/content/drive/MyDrive/Colab Notebooks/data/image/test_2000/'\n",
    "\n",
    "if not os.path.exists(dst):\n",
    "  os.makedirs(dst)\n",
    "\n",
    "for image in tqdm(test_path_2000):\n",
    "    source = src + image + '.jpg'\n",
    "    destination = dst + image + '.jpg'\n",
    "\n",
    "    shutil.copyfile(source, destination)\n",
    "\n",
    "\n",
    "# csv 파일 추출\n",
    "train_10000_text = text_train[text_train.answer.isin(['yes', 'no']) & text_train.image_id.isin(train_path_10000)].reset_index(drop=True)\n",
    "train_10000_text.to_csv('./data/train_10000.csv', index=False)\n",
    "\n",
    "test_2000_text = text_train[text_train.answer.isin(['yes', 'no']) & text_train.image_id.isin(test_path_2000)].reset_index(drop=True)\n",
    "test_2000_text.to_csv('./data/test_2000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터 개수 확인\n",
    "path_tr = '/content/drive/MyDrive/Colab Notebooks/data/image/train_10000'\n",
    "path_te = '/content/drive/MyDrive/Colab Notebooks/data/image/test_2000'\n",
    "\n",
    "images_tr = glob.glob(f'{path_tr}/*.jpg')\n",
    "images_te = glob.glob(f'{path_te}/*.jpg')\n",
    "\n",
    "len(images_tr), len(images_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQADataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, transform, img_path, is_test=False):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.img_path = img_path\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_name = os.path.join(self.img_path, row['image_id'] + '.jpg') # 이미지\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        question = row['question'] # 질문\n",
    "        question = self.tokenizer.encode_plus(\n",
    "            question,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=32,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        if not self.is_test:\n",
    "            answer = row['answer'] # 답변\n",
    "            answer = self.tokenizer.encode_plus(\n",
    "                answer,\n",
    "                max_length=32,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt')\n",
    "            return {\n",
    "                # np.sqeeuze(): 차원이 1인 axis를 제거\n",
    "                'image': image.squeeze(),\n",
    "                'question': question['input_ids'].squeeze(),\n",
    "                'answer': answer['input_ids'].squeeze()\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'image': image,\n",
    "                'question': question['input_ids'].squeeze(),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQAModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(VQAModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.gpt2 = GPT2Model.from_pretrained('gpt2')\n",
    "        self.gpt2.resize_token_embeddings(vocab_size) # 추가한 [PAD] 토큰 반영\n",
    "\n",
    "        combined_features_size = 1000 + self.gpt2.config.hidden_size # resnet 출력 차원 + gpt2 출력 차원\n",
    "        self.classifier = nn.Linear(combined_features_size, vocab_size)\n",
    "\n",
    "    def forward(self, images, question):\n",
    "        image_features = self.resnet(images)\n",
    "        image_features = image_features.view(image_features.size(0),-1)\n",
    "\n",
    "        outputs = self.gpt2(question)\n",
    "        output_features = outputs.last_hidden_state # [batch, sequence, hidden]\n",
    "\n",
    "        image_features = image_features.unsqueeze(1).expand(-1, output_features.size(1),-1) # [batch, sequence, 1000]\n",
    "\n",
    "        combined = torch.cat([image_features, output_features], dim=-1) # [batch, sequence, 1000+hidden]\n",
    "        output = self.classifier(combined) # [batch, vocab_size]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/zerobase/DL_project/data/train_10000.csv')\n",
    "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/zerobase/DL_project/data/test_2000.csv')\n",
    "\n",
    "train_img_path = '/content/drive/MyDrive/Colab Notebooks/zerobase/DL_project/data/image/train_10000'\n",
    "test_img_path = '/content/drive/MyDrive/Colab Notebooks/zerobase/DL_project/data/image/test_2000'\n",
    "\n",
    "# dataset & dataloader\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "# 이미지 정규화 -> 오차역전파 시 gradient 계산을 수행할 때 데이터가 유사한 범위를 가지도록 하기 위함\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),          # 모든 이미지 픽셀 값을 0~1 범위로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),    # 각 채널별 평균(mean)을 뺀 뒤, 표준편차(std)로 나누어 정규화 진행 [R, G, B] -> -1 ~ 1 범위로 변환\n",
    "])\n",
    "\n",
    "train_dataset = VQADataset(train_df, tokenizer, transform, train_img_path, is_test=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습과 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    itr = 1\n",
    "    p_itr = 1000\n",
    "\n",
    "    for data in tqdm(loader, total=len(loader)):\n",
    "        images = data['image'].to(device)\n",
    "        question = data['question'].to(device)\n",
    "        answer = data['answer'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        '''\n",
    "        # outputs의 크기가 (배치 크기)x(클래스의 개수)이므로 열이 하나의 이미지의 대응되는 벡터를 나타냄\n",
    "        '''\n",
    "        outputs = model(images, question)\n",
    "\n",
    "        # output: [batch, sequence, vocab], answer : [batch, sequence]\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), answer.view(-1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        '''\n",
    "        # torch.max 함 : 텐서에서 최대값을 구하는 함수\n",
    "        # torch.max(input) -> Tensor\n",
    "        # torch.max(input, dim, keepdim=False, *, out=None) -> tuple (max, max_indices)\n",
    "        '''\n",
    "\n",
    "        # Accuracy calculation\n",
    "        _, preds = torch.max(outputs, dim=2)  # Get predicted token indices\n",
    "        mask = (answer != tokenizer.pad_token_id)  # 패딩 토큰 무시\n",
    "\n",
    "        correct_predictions += torch.sum(preds[mask] == answer[mask])\n",
    "        total_predictions += mask.sum()\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % p_itr == 0:\n",
    "            print('Iteration {} -> Accuracy: {:.4f}'.format(itr, correct_predictions / total_predictions))\n",
    "        itr+=1\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, total=len(loader)):\n",
    "            images = data['image'].to(device)\n",
    "            question = data['question'].to(device)\n",
    "\n",
    "            outputs = model(images, question) # [batch, sequence, vocab]\n",
    "\n",
    "            _, pred = torch.max(outputs, dim=2) # values, indices = _, pred\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 코드 실행(학습)\n",
    "- lr : learning rate (1e-3, 1e-4, 1e-5) 변경\n",
    "- batch_size : batch size (8, 16, 32, 64) 변경 → 데이터 로더에서 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"current device is {device}\")\n",
    "\n",
    "# Model\n",
    "model = VQAModel(vocab_size).to(device)\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.CrossEntropyLoss에는 이미 nn.LogSoftmax가 포함되어 있다. 따라서 log값이 씌워진 output값이 아닌 생 output값을 줘야함\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    avg_loss, accuracy = train(model, train_loader, optimizer, criterion)\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    print('----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 데이터 answer 생성 후 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset & DataLoader\n",
    "test_dataset = VQADataset(test_df, tokenizer, transform, test_img_path, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# inference\n",
    "preds = inference(model, test_loader)\n",
    "\n",
    "no_pad_output = []\n",
    "for pred in preds:\n",
    "    output = pred[pred != 50257] # [PAD] token 제외\n",
    "    no_pad_output.append(tokenizer.decode(output).strip()) # 토큰 id -> 토큰\n",
    "\n",
    "test_df['predict_answer'] = no_pad_output\n",
    "test_df.to_csv('test_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.read_csv('test_result.csv')\n",
    "solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
